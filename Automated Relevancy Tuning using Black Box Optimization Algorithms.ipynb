{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#solrpy library: http://pythonhosted.org/solrpy/overview.html\n",
    "import solr #to install: pip install solrpy\n",
    "#pandas library for data processing - only needed to index the solr core, can be removed otherwise\n",
    "import pandas as pd #to install: pip install pandas\n",
    "#scikit-optimize library: https://github.com/scikit-optimize\n",
    "import skopt #to install: pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Settings\n",
    "\n",
    "# The files below are in the root folder of this GitHub repo. Launch jupyter notebook from that folder\n",
    "# in order to read these files: 'jupyter notebook'\n",
    "\n",
    "# Note: this is an artificial set of jobs, these are not real jobs, but are representative of our data\n",
    "# Job descriptions are omitted, but usually we search that field also\n",
    "jobs_data_file = \"jobs.csv\"\n",
    "\n",
    "# File of relevancy judgements - these are highly subjective judgements, please don't take them too seriously\n",
    "relevancy_file = \"relevancy_judegements.csv\"\n",
    "\n",
    "#solr url and core (Jobs)\n",
    "solr_url = \"http://localhost:8983/solr/Jobs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Jobs Data, Index in Solr Jobs Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitle</th>\n",
       "      <th>jobSkills</th>\n",
       "      <th>employer</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>geoCode</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Developer</td>\n",
       "      <td>[Project management, Java, Programming, QA]</td>\n",
       "      <td>IT Services and Networking Corp.</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>40.7127837,-74.0059413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cloud Developer</td>\n",
       "      <td>[QA, Software engineering, Compiler, Network, ...</td>\n",
       "      <td>Large Search Giant Llc.</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>IA</td>\n",
       "      <td>41.6005448,-93.6091064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Application Developer</td>\n",
       "      <td>[J2EE, Oracle, XML, QA, jQuery, JDBC, BIND, IBM]</td>\n",
       "      <td>Acme Inc</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>IA</td>\n",
       "      <td>41.6005448,-93.6091064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Application Developer</td>\n",
       "      <td>[Programming, Lifecycle management, Network]</td>\n",
       "      <td>IT Services and Networking Corp.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>41.8781136,-87.6297982</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pega Developer</td>\n",
       "      <td>[QA, Agile, Architecture]</td>\n",
       "      <td>Scientists and Quants Inc</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>40.7127837,-74.0059413</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                jobTitle                                          jobSkills  \\\n",
       "0         Lead Developer        [Project management, Java, Programming, QA]   \n",
       "1        Cloud Developer  [QA, Software engineering, Compiler, Network, ...   \n",
       "2  Application Developer   [J2EE, Oracle, XML, QA, jQuery, JDBC, BIND, IBM]   \n",
       "3  Application Developer       [Programming, Lifecycle management, Network]   \n",
       "4         Pega Developer                          [QA, Agile, Architecture]   \n",
       "\n",
       "                           employer        city state                 geoCode  \\\n",
       "0  IT Services and Networking Corp.    New York    NY  40.7127837,-74.0059413   \n",
       "1           Large Search Giant Llc.  Des Moines    IA  41.6005448,-93.6091064   \n",
       "2                          Acme Inc  Des Moines    IA  41.6005448,-93.6091064   \n",
       "3  IT Services and Networking Corp.     Chicago    IL  41.8781136,-87.6297982   \n",
       "4         Scientists and Quants Inc    New York    NY  40.7127837,-74.0059413   \n",
       "\n",
       "   id  \n",
       "0   0  \n",
       "1   1  \n",
       "2   2  \n",
       "3   3  \n",
       "4   4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: You can skip this section if you were able to load the Solr Jobs Core along with the data directory from the \n",
    "# './Solr Core and Config' sub-folder. Older versions of Solr won't read this data, so here's some code to populate \n",
    "# the index from the jobs.csv file\n",
    "\n",
    "jobs_df = pd.read_csv(jobs_data_file, sep=\",\")\n",
    "jobs_df[\"jobSkills\"] = jobs_df[\"jobSkills\"].apply(lambda sk: sk.split(\"|\"))\n",
    "# assign a unique doc id to each row\n",
    "jobs_df[\"id\"] = range(len(jobs_df))\n",
    "jobs_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<response>\\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">0</int></lst>\\n</response>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solr_connection = solr.Solr(solr_url, persistent=True, timeout=360, max_retries=5)\n",
    "\n",
    "# convert dataframe to a list of dictionaries (required solr client library document format)\n",
    "docs = jobs_df.T.to_dict().values()\n",
    "\n",
    "#wipe out any existing documents if present\n",
    "solr_connection.delete_query(\"*:*\")\n",
    "\n",
    "# send documents\n",
    "solr_connection.add_many(docs)\n",
    "\n",
    "# hard commit and optimize\n",
    "solr_connection.commit()\n",
    "solr_connection.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Relevancy Judgements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>fq</th>\n",
       "      <th>location</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>java developer</td>\n",
       "      <td>{!geofilt}&amp;sfield=geoCode&amp;pt=41.884251,-87.632...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>8,20,27,52,127,159,194,354,364,414,485,499,677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data warehouse</td>\n",
       "      <td>{!geofilt}&amp;sfield=geoCode&amp;pt=41.884251,-87.632...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>1078,1996,254,254,870,1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>web services</td>\n",
       "      <td>{!geofilt}&amp;sfield=geoCode&amp;pt=40.7127837, -74.0...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1342,1449,395,1272,1512,54,608,1528,38,84,150,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            query                                                 fq  \\\n",
       "0  java developer  {!geofilt}&sfield=geoCode&pt=41.884251,-87.632...   \n",
       "1  data warehouse  {!geofilt}&sfield=geoCode&pt=41.884251,-87.632...   \n",
       "2    web services  {!geofilt}&sfield=geoCode&pt=40.7127837, -74.0...   \n",
       "\n",
       "       location                                           relevant  \n",
       "0   Chicago, IL  8,20,27,52,127,159,194,354,364,414,485,499,677...  \n",
       "1   Chicago, IL                         1078,1996,254,254,870,1968  \n",
       "2  New York, NY  1342,1449,395,1272,1512,54,608,1528,38,84,150,...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 'relevant' column is a list of document id's (the id field from the schema) that were both in the set of the top\n",
    "# 20 returned documents, and were subjectively judged as relevant to the original\n",
    "# query. We can subsequently use these to derive a MAP score for a given query\n",
    "\n",
    "rel_df = pd.read_csv(relevancy_file, sep=\"|\", converters={\"fq\": str, \"location\": str})\n",
    "searches = rel_df.T.to_dict()\n",
    "rel_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Takes a search id and a qf setting, and returns the list of doc ids, \n",
    "def get_results_for_search(sid, qf_value):\n",
    "    search = searches[sid]\n",
    "    fq = \"\"\n",
    "    pt = \"0,0\"\n",
    "    \n",
    "    if not search[\"location\"].strip() == \"\" :\n",
    "        splt = filter(lambda s: \"pt=\" in s, search[\"fq\"].split(\"&\"))\n",
    "        if splt:\n",
    "            pt = splt[0].replace(\"pt=\",\"\")\n",
    "            fq = \"{!geofilt}\"\n",
    "\n",
    "    resp = solr_connection.select(\n",
    "       q=search[\"query\"], \n",
    "       fields=\"id\",\n",
    "       start=0, rows=20, \n",
    "       qf=qf_value, # comes from get_solr_params\n",
    "       fq=fq,\n",
    "       sfield=\"geoCode\",\n",
    "       pt=pt,\n",
    "       score=False,\n",
    "       d=\"48.00\", wt=\"json\")\n",
    "    predicted = list(map(lambda res: res[\"id\"], resp.results))\n",
    "    # return predicted doc ids, along with relevent ones (for IR metric)\n",
    "    return predicted, list(map(int, search[\"relevant\"].split(\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : set\n",
    "             A set of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mean_average_precision_at_k(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of sets of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Box Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function takes a list of 12 real numbers, and returns a set of solr configuration options\n",
    "def get_solr_params(params):\n",
    "    return {\"qf\" : \"employer^{0}  jobTitle^{1}  jobskills^{2}\".format(*params[0:3])\n",
    "            #\"pf2\" :  \"employer^{0}  jobTitle^{1}  jobSkills^{2}\".format(*params[3:6]), \n",
    "            #\"pf\"  :  \"employer^{0}  jobTitle^{1}  jobSkills^{2}\".format(*params[6:9]) \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spit into training and test set of queries\n",
    "sids = list(searches.keys())\n",
    "cutoff = len(sids) /2 \n",
    "train_sids, test_sids = sids[:cutoff], sids[cutoff:]\n",
    "train_sids, test_sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Precision cut off\n",
    "PREC_AT = 20\n",
    "# Black box objective function to minimize\n",
    "def objective(params):\n",
    "    # map list of numbers into solr parameters (just qf in this case)\n",
    "    additional_params = get_solr_params(params)\n",
    "    \n",
    "    predicted, actual =[],[]\n",
    "    for sid in train_sids:\n",
    "        pred, act = get_results_for_search(sid, additional_params[\"qf\"])\n",
    "        predicted.append(pred)\n",
    "        actual.append(act)\n",
    "    # Compute Mean average precision at 20\n",
    "    return -1.0 * mean_average_precision_at_k(actual, predicted, PREC_AT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Optimizer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call back function to track progress\n",
    "def callback(res):\n",
    "    call_no = len(res.func_vals)\n",
    "    current_fun = res.func_vals[-1]\n",
    "    best = np.min(res.func_vals)\n",
    "    MAP = -1.0 * best\n",
    "    star = \"\"\n",
    "    if best == current_fun:\n",
    "        star = \"*\" * 4\n",
    "    print str(call_no).ljust(5) + \"\\t\" + str(MAP).ljust(20) + \"\\t\" + \\\n",
    "        str(-1.0* current_fun).ljust(20) + \"\\t\" + str(map(lambda d: round(d,3), res.x_iters[-1])) + \"\\t\" + star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.74894708994708992"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute results at current production settings\n",
    "prod_map = objective([1.8,1,1])\n",
    "prod_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at  2016-10-12 17:56:49.837279\n",
      "Run \tBest MAP \t\tCurrent MAP \t\tParameters\n",
      "1    \t0.834923613424      \t0.834923613424      \t[7.633, 4.669, 11.146]\t****\n",
      "2    \t0.834923613424      \t0.573333333333      \t[15.118, 3.984, 9.322]\t\n",
      "3    \t0.834923613424      \t0.834923613424      \t[3.102, 29.481, 19.532]\t****\n",
      "4    \t0.834923613424      \t0.834923613424      \t[22.993, 17.167, 9.658]\t****\n",
      "5    \t0.834923613424      \t0.834923613424      \t[41.763, 49.444, 30.546]\t****\n",
      "6    \t0.834923613424      \t0.834923613424      \t[46.35, 31.324, 44.14]\t****\n",
      "7    \t0.834923613424      \t0.834923613424      \t[36.349, 34.089, 31.117]\t****\n",
      "8    \t0.834923613424      \t0.834923613424      \t[38.425, 27.613, 12.656]\t****\n",
      "9    \t0.834923613424      \t0.834923613424      \t[13.46, 13.443, 8.997]\t****\n",
      "10   \t0.834923613424      \t0.834923613424      \t[32.201, 18.663, 40.82]\t****\n",
      "MAP @20 PROD   = 0.748947089947\n",
      "MAP @20 GP OPT = 0.834923613424\n"
     ]
    }
   ],
   "source": [
    "from skopt import gbrt_minimize\n",
    "import datetime\n",
    "\n",
    "ITERATIONS = 500 # probably want this to be high, 500 or more\n",
    "min_val, max_val = 0.0, 50.0\n",
    "space  = [(min_val, max_val) for i in range(3)] # min and max for each possible qf value\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print \"Starting at \", start\n",
    "\n",
    "print \"Run\",\"\\t\", \"Best MAP\", \"\\t\\t\", \"Current MAP\", \"\\t\\t\", \"Parameters\"\n",
    "# run optimizer\n",
    "res = gbrt_minimize(objective,       # the function to minimize\n",
    "                  space,             # the bounds on each dimension of x\n",
    "                  acq=\"LCB\",         # controls how it searches for parameters\n",
    "                  n_calls=ITERATIONS,# the number of evaluations of f including at x0\n",
    "                  random_state=777,  # set to a fixed number if you want this to be deterministic\n",
    "                  n_jobs=-1,         # how many threads (or really python processes due to GIL)\n",
    "                  callback=callback) \n",
    "\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP @20 PROD      = 0.748947089947\n",
      "MAP @20 OPTIMIZED = 0.834923613424\n",
      "\n",
      "Parameters:\n",
      "\temployer^7.63318674507  jobTitle^4.66866284146  jobskills^11.1464049498\n",
      "\n",
      "gbrt_minimize took 0.122591 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP @\" + str(PREC_AT) + \" PROD      = \" +  str(-1 * prod_map))\n",
    "print(\"MAP @\" + str(PREC_AT) + \" OPTIMIZED = \" +  str(-1 * res.fun))\n",
    "print(\"\\nParameters:\\n\\t\"),\n",
    "print get_solr_params(res.x)[\"qf\"]\n",
    "print \"\\ngbrt_minimize took\", (end - start).total_seconds(), \"secs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
